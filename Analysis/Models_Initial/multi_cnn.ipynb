{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and select trainging hour and test hour\n",
    "trainhour = 6\n",
    "testhour = 9\n",
    "df = pd.read_csv('series.csv')\n",
    "cols5 = ['21', '22', '23', '24', '25']\n",
    "cols10 = ['21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
    "df['sum5'] = df[cols5].sum(axis=1)\n",
    "df['sum10'] = df[cols10].sum(axis=1)\n",
    "data = df.drop(df[(df['hour'] != trainhour)].index)\n",
    "testdata = df.drop(df[(df['hour'] != testhour)].index)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Categorize the 'sum' column the number of PIPs over selected range\n",
    "def setlabels(x, y):\n",
    "    if x < -3:\n",
    "        if y < -10:\n",
    "            return 1\n",
    "        elif y > 10:\n",
    "            return 2\n",
    "        else:\n",
    "            return 5\n",
    "    elif x > 3:\n",
    "        if y < 10:\n",
    "            return 3\n",
    "        elif y > 10:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "data[\"labels\"] = data.apply(lambda x: setlabels(x.sum5, x.sum10), axis=1)\n",
    "testdata[\"labels\"] = testdata.apply(lambda x: setlabels(x.sum5, x.sum10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X, y for model\n",
    "X = data.iloc[:,8:28].to_numpy()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "y = data['labels']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "y_encoded = label_encoder.transform(y)\n",
    "y = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc4194ca58>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train, epochs=5, shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.5074039144679712, Accuracy: 0.837596595287323\n",
      "Normal Neural Network - Loss: 0.5437814797726522, Accuracy: 0.8416580557823181\n"
     ]
    }
   ],
   "source": [
    "# Model loss and Accuray\n",
    "model_loss, model_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out validation data and make predicts\n",
    "formodel = testdata.iloc[:,8:28].to_numpy()\n",
    "testdata['predict'] = label_encoder.inverse_transform(model.predict_classes(formodel))\n",
    "testdata = testdata.drop(testdata[(testdata['predict'] == 5)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.29999999999999"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalrows = testdata.shape[0]\n",
    "totalcols = testdata.shape[1]\n",
    "profit = []\n",
    "for i in range(totalrows):\n",
    "    temp = 0\n",
    "    if ((testdata.iloc[i,totalcols-1] == 1) | (testdata.iloc[i,totalcols-1] == 2)):\n",
    "        for j in range(10):\n",
    "            temp -= testdata.iloc[i,28+j]\n",
    "            if((temp < -2) | (temp > 15)):\n",
    "              break\n",
    "    else:\n",
    "        for j in range(10):\n",
    "            temp += testdata.iloc[i,28+j]\n",
    "            if((temp < -2) | (temp > 15)):\n",
    "              break\n",
    "    profit.append(temp)\n",
    "\n",
    "testdata['profit'] = profit\n",
    "testdata['profit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata.to_csv('binarytest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 36 (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
